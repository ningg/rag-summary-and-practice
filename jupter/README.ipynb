{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bccd2a8",
   "metadata": {},
   "source": [
    "# rag-summary-and-practice\n",
    "RAG 技术要点、本地实践\n",
    "\n",
    "## 0.背景\n",
    "\n",
    "最近几周工作上，接触些 RAG 内容，看了点资料；本着`最好的学习是复述`原则，把所有要点，重新梳理下。\n",
    "\n",
    "思路：\n",
    "\n",
    "1.RAG 解决什么问题？\n",
    "2.RAG 核心原理、核心组件\n",
    "3.RAG 高级技术，不同组件的进阶\n",
    "4.效果评估\n",
    "5.后续发展方向\n",
    "\n",
    "## 1.RAG 解决什么问题\n",
    "\n",
    "LLM 基于大规模数据的预训练，获取的通用知识。对于`私有数据`和`高频更新数据`，LLM 无法及时更新。如果采用 `Fine-Tuning` 监督微调方式，LLM 训练成本也较高，而且无法解决`幻觉`问题。 \n",
    "\n",
    "即，`私有数据`和`高频更新数据`，以及`幻觉`问题，LLM 模型自身解决成本较高，因此，引入 RAG `Retrieval Augmented Generation`。\n",
    "\n",
    "\n",
    "## 2.核心原理\n",
    "\n",
    "RAG 检索增强生成：通过检索`外部数据源`信息，构造`融合上下文`（Context），输入给 LLM，获取更准确的结果。\n",
    "\n",
    "核心环节：\n",
    "\n",
    "a. 索引（indexing）\n",
    "b. 检索（retrieval）\n",
    "c. 生成（generation）\n",
    "\n",
    "\n",
    "下述 RAG 架构图中，出了上面 3 个核心环节，还有：查询优化、路由、查询构造\n",
    "\n",
    "* 查询优化（Query Translation）：查询重写、查询扩展、预查伪文档；\n",
    "* 路由（Routing）：根据查询，判断从哪些数据源，获取信息；\n",
    "* 查询抽取（Query Construction）：从原始 Query 中，抽取 SQL 、 Cypher、metadatas，分别用于 关系数据库、图数据库、向量数据库的查询。\n",
    "\n",
    "![rag_detail_v2](../img/rag-overview.png)\n",
    "\n",
    "\n",
    "开始之前，先在本地安装好 Ollama，并且下载好 embedding model 和 language model。\n",
    "\n",
    "* TODO：增加一个链接.\n",
    "\n",
    "安装依赖：\n",
    "\n",
    "* TODO 增加 python 依赖以及版本？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "013b3b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (0.3.29)\n",
      "Requirement already satisfied: tiktoken in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (0.11.0)\n",
      "Requirement already satisfied: langchain-ollama in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (0.3.7)\n",
      "Requirement already satisfied: langchainhub in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (0.1.21)\n",
      "Requirement already satisfied: chromadb in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (1.0.20)\n",
      "Requirement already satisfied: langchain in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (0.3.75)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.6.7 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (0.4.21)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain_community) (2.3.2)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from dataclasses-json<0.7,>=0.6.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from tiktoken) (2025.8.29)\n",
      "Requirement already satisfied: ollama<1.0.0,>=0.5.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchain-ollama) (0.5.3)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from ollama<1.0.0,>=0.5.3->langchain-ollama) (0.28.1)\n",
      "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langchainhub) (2.32.4.20250809)\n",
      "Requirement already satisfied: build>=1.0.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.36.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (1.74.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (0.17.3)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (3.11.3)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from chromadb) (4.25.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: anyio in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (0.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from rsa<5,>=3.1.4->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
      "Requirement already satisfied: coloredlogs in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
      "Requirement already satisfied: protobuf in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (6.32.0)\n",
      "Requirement already satisfied: sympy in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from tokenizers>=0.13.2->chromadb) (0.34.4)\n",
      "Requirement already satisfied: filelock in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.9)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from anyio->httpx>=0.27->ollama<1.0.0,>=0.5.3->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/guoning/anaconda3/envs/ragEco/lib/python3.13/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community tiktoken langchain-ollama langchainhub chromadb langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eea0ef1",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1. RAG Oveview\n",
    "\n",
    "完整的 indexing、retrieval、generation 实例代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934237f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] input_types={} partial_variables={} metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n",
      "<think>\n",
      "Okay, I'm trying to figure out what Task Decomposition is based on the context provided. Let me start by reading through the context carefully.\n",
      "\n",
      "So, the first part talks about Component One: Planning#. It says that a complicated task usually involves many steps and an agent needs to know what they are and plan ahead. That makes sense; planning is essential for tackling complex tasks.\n",
      "\n",
      "Next, Task Decomposition# is introduced. It mentions Chain of Thought (CoT) which is a prompting technique used to enhance model performance on complex tasks. The idea is that the model thinks step by step, using more computation time to break down hard tasks into smaller, manageable steps. CoT turns big tasks into multiple simpler ones and gives insight into how the model thinks.\n",
      "\n",
      "Then there's Tree of Thoughts (Yao et al., 2023), which extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into multiple thought steps and generates a tree structure, allowing for different search methods like BFS or DFS. Each state is evaluated by a classifier or majority vote.\n",
      "\n",
      "Task decomposition can be done in three ways: (1) using LLMs with simple prompts like \"Steps for XYZ.\\n1.\" or asking for subgoals; (2) using task-specific instructions, such as \"Write a story outline.\" for writing a novel; and (3) by integrating human inputs. Additionally, there's LLM+P approach (Liu et al., 2023), which uses an external classical planner with PDDL, translating the problem into PDDL, requesting a plan, then converting it back to natural language.\n",
      "\n",
      "Putting this together, Task Decomposition is a method used by AI models to break down complex tasks into smaller, more manageable steps. This allows for better planning and execution by considering multiple possibilities and using both internal prompts and external tools or human input.\n",
      "</think>\n",
      "\n",
      "Task decomposition is the process of breaking down complex tasks into simpler, more manageable subtasks. This approach helps in planning and executing tasks effectively by identifying each step required to achieve the overall goal. It can be facilitated through techniques like Chain of Thought or Tree of Thoughts, which allow for exploring multiple reasoning paths. Task decomposition can also involve external tools or human input, depending on the task's complexity and domain.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "\n",
    "#### 1.INDEXING ####\n",
    "\n",
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Embed\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "#### 2.RETRIEVAL and 3.GENERATION ####\n",
    "\n",
    "# Prompt\n",
    "# Pull a pre-made RAG prompt from LangChain Hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)\n",
    "\n",
    "# LLM\n",
    "llm = OllamaLLM(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# Post-processing\n",
    "# Helper function to format retrieved documents\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Helper function to remove <think> part in the text\n",
    "def remove_think_tags(text):\n",
    "    \"\"\"remove <think> part in the text\"\"\"\n",
    "    cleaned_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL)\n",
    "    cleaned_text = re.sub(r'\\n\\s*\\n', '\\n', cleaned_text)\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "# RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    # | remove_think_tags\n",
    ")\n",
    "\n",
    "# Question\n",
    "# Ask a question using the RAG chain\n",
    "response = rag_chain.invoke(\"What is Task Decomposition?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb616381",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2. Indexing\n",
    "\n",
    "几个方面：\n",
    "\n",
    "1. Tokenizer：分词，文本会被拆分成 token，映射到词表中 tokenID。\n",
    "2. Embedding：嵌入，将 tokenID 映射到向量空间中，得到 token 的向量表示。\n",
    "3. Chunk：分块，将文本拆分成多个 chunk，每个 chunk 包含多个 token。\n",
    "4. Index：索引，将 chunk 的向量表示存储到向量数据库中。\n",
    "\n",
    "#### 2.2.1.Token\n",
    "\n",
    "更多细节， [Count tokens](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) and [~4 char / token](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)\n",
    "\n",
    "> TODO: token 的扩展信息，参考上面链接.\n",
    "\n",
    "查看下面分词得到的 Token："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db4639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenIDs: [3923, 13124, 315, 26159, 656, 358, 1093, 30]\n",
      "token num: 8\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Documents\n",
    "document = \"My favorite pet is a cat.\"\n",
    "question = \"What kinds of pets do I like?\"\n",
    "\n",
    "# count token num\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    tokenIDs = encoding.encode(string)\n",
    "\n",
    "    print('tokenIDs: ' + str(tokenIDs))\n",
    "\n",
    "    num_tokens = len(tokenIDs)\n",
    "    return num_tokens\n",
    "\n",
    "# use cl100k_base encoding\n",
    "result = num_tokens_from_string(question, \"cl100k_base\")\n",
    "print('token num: ' + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dfd2ce",
   "metadata": {},
   "source": [
    "\n",
    "#### 2.2.2.Embedding\n",
    "\n",
    "[Ollama Embedding](https://python.langchain.com/docs/integrations/text_embedding/ollama/) ，实例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b36e85b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_result: [-0.039018694, 0.031094884, -0.16405655, -0.05365974, 0.029023448, 0.081135996, -0.07435195, -0.024100842, -0.057076577, -0.030934965, -0.01667621, 0.06981713, 0.022757139, 0.008057768, -0.0612419, -0.05746149, 0.0015947915, -0.087047115, 0.080221325, 0.058845446, -0.00096579356, 0.015772853, 0.025487997, -0.02524609, 0.10920839, 0.0638827, -0.04042057, 0.015808905, 0.034302182, 0.03659333, -0.020421792, -0.022445455, -0.00062922004, 0.02146923, 0.029062167, 0.011029808, 0.06911333, 0.020991126, 0.036185347, 0.07025371, 0.04456468, 0.038009495, 0.027982961, 0.018861063, 0.046728056, -0.06053096, 0.07686234, -0.036467824, 0.055864576, -0.0058690845, 0.057870295, -0.020560548, -0.02736173, -0.035338487, 0.055048063, -0.03251455, 0.043848973, -0.046494257, -0.000107465836, -0.009190778, 0.05482503, 0.0227895, -0.034663882, 0.040489357, 0.01651332, -0.029101133, -0.03218672, 0.0493623, -0.03330113, -0.0051744464, 0.036488034, 0.0048338627, 0.06140954, 0.03279879, -0.009941136, 0.02144728, -0.0067423573, -0.051313918, 0.02439488, 0.0001620967, 0.042411532, -0.0047389343, 0.035728317, -0.025668852, 0.007533799, -0.030760288, -0.02661243, -0.019673785, -0.027719911, 0.043510746, -0.02671427, -0.021407165, 0.038041282, 0.013619413, -0.0820724, 0.03195209, -0.036017243, 0.0022051008, 0.015187919, -0.050246675, -0.028921414, -0.00029372243, 0.018575905, 0.020603847, 0.04412895, 0.04337072, -0.02348409, -0.011119822, -0.017852604, 0.014259172, -0.056468822, 0.04161716, -0.018733503, -0.0022589536, -0.029099287, 0.033930354, -0.0006445045, -0.03854773, 0.048888188, 0.09006618, 0.032279313, -0.043470167, 0.025782712, 0.02488316, 0.0029878747, -0.025737794, -0.027642762, 0.02071813, -0.0061910455, 0.010651807, 0.040324695, -0.033238325, 0.016276184, -0.039308213, 0.003017261, 0.057057567, 0.00043359806, -0.04309189, 0.037851878, 0.028108155, 0.062258758, 0.037258636, 0.02292015, 0.0058546015, -0.017949339, -0.04604914, 0.0032383308, -0.021790834, 0.0026222374, 0.032973614, -0.0057843192, 0.019077882, -0.015202036, 0.027523993, -0.008797585, -0.07054703, -0.009585597, 0.027783364, -0.020386638, 0.015155528, 0.03159741, -0.05664917, -0.049825996, 0.038913675, 0.051893268, -0.00484858, 0.025131065, 0.04260518, 0.0042476477, 0.09456652, -0.024017526, -0.0051272917, -0.024140656, -0.0032041303, 0.05905404, -0.08337515, -0.025037974, -0.028375467, 0.00023504622, -0.05607064, 0.013505998, -0.049601085, -0.05057519, 0.024949715, -0.032497346, 0.00578274, -0.0009817088, 0.0054876017, -0.056873765, -0.039369114, -0.004302137, 0.0126693165, -0.025311077, -0.027230326, -0.025508644, -0.020314692, 0.001130827, 0.00079131615, -0.016688827, -0.043023955, 0.008362552, -0.0004737522, -0.04642068, 0.010352406, -0.086495675, 0.027090102, -0.014493872, 0.040391326, 0.024244748, 0.0026406436, 0.07682995, -0.053010326, -0.05423138, 0.009316757, -0.046898838, -0.015370701, -0.03537927, 0.0011242168, -0.055670805, 0.030853424, 0.086389475, -0.009885377, -0.010164492, -0.05611917, 0.0555686, 0.004272957, 0.0007396652, 0.026027314, -0.0075085917, 0.021311413, -0.0008465557, -0.036423244, 0.10425901, -0.026696485, 0.0045727594, 0.022627363, 0.047826782, 0.0016877996, -0.028526215, -0.04598253, 0.005711253, 0.007887026, 0.009540838, -0.015546569, -0.0650939, -0.016436266, -0.044338122, -0.010740069, -0.023502788, 0.03897222, -0.007194248, 0.0031595957, 0.051418923, 0.035838086, 0.020365741, -0.03635335, -0.016104165, 0.013957256, 0.021525443, -0.009089738, 0.049994547, -0.008553371, -0.0033435905, -0.040029604, -0.0056337663, -0.012567856, -0.0139689995, 0.040493183, 0.03024051, -0.005134572, 0.0475974, 0.0085054925, -0.0137358215, 0.0022727735, -0.0041616936, 0.06758556, -0.032004226, 0.004481658, -0.032862686, -0.018416766, 0.06494186, -0.026764646, -0.033193897, -0.015606162, -0.00488077, 0.036095947, 0.035425033, 0.0011773285, 0.0002745902, 0.023887472, -0.03127925, 0.0051452257, -0.016713059, 0.02850236, -0.0046313177, -0.028835962, 0.045229584, -0.0011569356, -0.007202497, 0.01441052, -0.013489308, 0.00952786, 0.06089462, -0.007046849, 0.011249415, 0.008391511, 0.042517204, 0.008027257, 0.050447065, 0.014015698, -0.06517503, 0.00017006809, -0.030762207, 0.0052066036, -0.044302803, 0.03184969, 0.018228529, -0.01381712, 0.03502253, -0.014093024, -0.023423765, -0.031482678, 0.027032632, -0.05228701, 0.048446983, 0.049081754, 0.014871332, 0.032034926, -0.018739128, -0.020762254, 0.005531748, 0.03209643, 0.0057382477, -0.040075444, -0.077228546, 0.03470633, 0.042327106, 0.021980003, -0.0054872097, 0.025344964, 0.06762711, -0.011761473, 0.037569594, -0.079352856, -0.061049577, -0.03690983, -0.030680593, -0.018444074, 0.03803813, 0.0038890413, -0.044885848, 0.02237881, 0.037634432, -0.0028102654, 0.016579026, -0.06225229, -0.03309582, 0.007830224, -0.046629496, -0.008269498, -0.0021432815, -0.0013510021, -0.0022254146, -0.03944846, -0.007901349, -0.0034885972, 0.007599412, -0.0141927255, -0.0054894313, -0.0031563884, 0.0048807743, 0.015534565, 0.016293108, -0.0034220319, 0.028980652, 0.047797948, -0.052977465, -0.018641671, -0.07253796, -0.04689026, -0.002759367, -0.016951773, -0.0032572735, 0.010162892, -0.00038704593, 0.032492943, -0.008612485, 0.025044614, 0.004072615, -0.015927792, -0.012793602, -0.0061487625, -0.079877906, -0.06477249, 0.021542596, -0.04511136, 0.10332738, -0.047311332, 0.010467665, 0.06482478, -0.004774489, -0.027849646, 0.0012352433, -0.033768423, -0.0007733993, 0.08958971, -0.02658669, -0.04198161, 0.001958802, -0.009887622, -0.015340573, 0.061933916, 0.043282494, -0.013589877, 0.002944766, 0.029767029, -0.02913196, 0.0073746685, -0.007054238, -0.03392693, 0.011170384, 0.016472058, -0.005288359, -0.0039042544, -0.0446835, -0.026092382, 0.045801178, 0.0505239, -0.03941885, -0.061372314, 0.026848322, -0.028174944, 0.021016918, 0.02267984, 0.020245772, 0.018343244, -0.02455145, 0.022386825, -0.0011060715, 0.0551211, 0.058623236, -0.025115622, -0.011672349, -0.043794584, 0.025749607, 0.022976337, 0.022024529, -0.032685064, -0.04772941, 0.029817192, -0.036166996, 0.010331854, 0.01770339, -0.0020534843, 0.039491963, -0.0027719426, 0.017879926, 0.002208852, 0.047940828, 0.029556839, 0.022102457, 0.019734116, -0.032379415, 0.0017604871, 0.00943269, -0.007083601, 0.009785191, -0.01542381, 0.01305101, 0.028918702, 0.012845655, 0.0054552727, 0.037277512, 0.010854993, -0.043614607, -0.0023042532, -0.0050082873, 0.0050830566, -0.009281359, 0.04836019, -0.018507577, -0.006301939, -0.026192825, -0.052460622, 0.00943391, -0.015347283, 0.04576627, 0.003338425, 0.0055307657, -0.0023122078, -0.014070339, 0.019677676, 0.041003518, -0.027606534, -0.019247787, 0.004651008, -0.012307605, 0.018147048, 0.077663824, 0.001177829, 0.012753825, -0.002420197, -0.04024379, 0.026698185, 0.046159845, 0.030296749, 0.0065755555, -0.09910255, -0.032576602, -0.031798605, -0.02661921, -0.0169701, -0.040273, 0.07745123, -2.599677e-05, -0.032375686, 0.02524074, 0.06157161, 0.01813735, 0.023433758, 0.012319543, -0.03742559, -0.013828161, -0.005604978, -0.024754545, 0.011020455, -0.005759641, -0.020740854, 0.018939642, -0.03364817, 0.030758103, -0.021366592, -0.011203504, 0.0014264787, -0.023780586, -0.0007404483, -0.045684587, 0.058314875, 0.010827485, -0.025256, 0.022880508, 0.017608926, -0.0002483565, 0.026247445, 0.01558472, -0.009473616, -0.042175937, 0.030262671, -0.012859745, 0.001478984, 0.055604577, -0.093744606, -0.017090855, -0.04759116, 0.00799077, -0.06372587, -0.032026872, 0.042892307, 0.0099833775, -0.014636349, -0.00025700402, 0.056180473, 0.025419828, 0.004881493, 0.027933644, 0.020140298, -0.02958547, 0.008052178, 0.0025670193, -0.0067536887, -0.017845025, 0.0070451126, -0.03594559, -0.024526006, 0.045342796, -0.050654314, 0.002052064, 0.02182457, -0.051551327, -0.012819399, 0.008998528, -0.03895549, -0.072978534, 0.03177594, -0.0013605924, -0.0021083644, 0.01509426, -0.052433766, -0.01494627, -0.025010591, -0.00090157194, -0.019595342, 0.014493016, -0.052130118, 0.052635033, 0.05542245, -0.0030835017, -0.0721078, -0.006923774, -0.059495334, 0.03219742, -0.02636706, 0.06767604, -0.0016144026, -0.048367452, 0.07129877, 0.0093254475, 0.043801133, -0.032908652, 0.015364182, 0.01357406, 0.015955823, -0.050068934, -0.028903557, 0.03737985, -0.0021551822, 0.05803175, -0.011523613, -0.012757521, -0.012461518, -0.0041619916, -0.023154892, 0.023428563, 0.017724073, 0.031019099, -0.0072695673, -0.07018699, -0.02534408, 0.027974034, 0.040511988, -0.025811946, 0.024802905, -0.09630277, -0.025444817, -0.0220015, 0.0025885222, -0.059899453, 0.017561747, -0.0024550033, 0.057097103, 0.08214871, 0.05043801, -0.036741037, 0.014486272, 0.020086538, 0.018038103, 0.07379824, 0.030388564, 0.049724963, -0.0051586586, 0.04502634, 0.07165828, 0.045322273, 0.002603171, 0.019560527, -0.0077595795, 0.036098946, -0.076864034, -0.052154377, -0.029620627, 0.0032124764, -0.00657515, -0.058243893, 0.042649392, 0.014466385, -0.0005259874, -0.04947666, -0.0038379994, -0.08836327, 0.025006894, 0.05913682, -0.022435278, -0.01995553, 0.0013019294, 0.014067249, -0.0017416188, -0.030568652, 0.02980665, 0.06683444, -0.0126192365, -0.022245003, -0.028378556, -0.017513404, 0.035914615, -0.074680306, 0.012674829, 0.02829119, -0.091810495, -0.016856425, -0.04332576, -0.019409655, -0.073317155, 0.023682572, 0.0016463157, -0.05211761, -0.026164634, -0.035941582, -0.004611716, -0.03009375, 0.039865177, 0.0007106918, 0.0634724, 0.04217514, 0.016402896, 0.007346556, -0.0365773, 0.0023905241, -0.00585688, 0.016229875, 0.012017782, -0.0057028094, 0.059018273, 0.047749612, 0.02402898, 0.03465951, 0.017861975, -0.0333016, -0.010115092, -0.06860628, -0.006088976, 0.015179771, 0.0018431405, -0.036164574, 0.009969062, -0.022758203, -0.027990684, 0.019694913, -0.07801162, -0.005353381, 0.031981587, -0.022538574, 0.018011188, -0.06845583, 0.005356464, -0.012647096, -0.0074258163, 0.030417398, -0.008222236, 0.014737512, -0.018156754, -0.013521198, 0.0228377, 0.016728843, 0.04323991, -0.028997382, 0.02746994, -0.0018436193, 0.03185105, 0.01480868, 0.01681837, 0.028893353, 0.01335739, -0.039716728, 0.008419017, -0.045585297, 0.056746893, 0.021555942, 0.088894404, 0.045899644, 0.014442096, 0.06770105, -0.04936446, 0.050694406, 0.013220709, -0.07616703, 0.026108883, -0.07768865, -0.033084996]\n",
      "embedding dim: 768\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embd = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "query_result = embd.embed_query(question)\n",
    "document_result = embd.embed_query(document)\n",
    "result = len(query_result)\n",
    "\n",
    "print('query_result: ' + str(query_result))\n",
    "print('embedding dim: ' + str(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29bfa5c",
   "metadata": {},
   "source": [
    "\n",
    "衡量 2 个 embedding 结果的关联关系，使用 `cosine similarity`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb12462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.748776300347665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "similarity = cosine_similarity(query_result, document_result)\n",
    "print(\"Cosine Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74333e",
   "metadata": {},
   "source": [
    "\n",
    "> TODO: 增加 cosine similarity 物理含义的说明.\n",
    "\n",
    "#### 2.2.3.Chunk\n",
    "\n",
    "LangChain 提供了关联工具：\n",
    "\n",
    "* [Document Loaders](https://python.langchain.com/docs/integrations/document_loaders/)：加载各类文档数据，并转换为 LangChain 的 Document 标准对象。\n",
    "* [Text Splitters](https://python.langchain.com/api_reference/text_splitters/index.html)：将文本拆分成多个 chunk，每个 chunk 包含多个 token。\n",
    "\n",
    "下面使用 `RecursiveCharacterTextSplitter` 进行分割："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0028557e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print splits 1: page_content='LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300, \n",
    "    chunk_overlap=50)\n",
    "\n",
    "# Make splits\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Print splits\n",
    "print(\"Print splits 1:\", splits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c3cda",
   "metadata": {},
   "source": [
    "\n",
    "> RecursiveCharacterTextSplitter: 原理细节，TODO\n",
    "\n",
    "\n",
    "#### 2.2.4.Index\n",
    "\n",
    "有多种向量数据库，下面使用 Chroma 进行演示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce0de64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7675f8ef",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3. Retrieval\n",
    "\n",
    "上面建好了索引，现在进行检索："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606dc0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1 documents\n",
      "page_content='Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.' metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w1/28b687hj1n1cngq28t956tzm0000gn/T/ipykernel_7963/3667342653.py:4: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")\n"
     ]
    }
   ],
   "source": [
    "# TODO: 参数含义\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "\n",
    "docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")\n",
    "\n",
    "print(f\"Retrieved {len(docs)} documents\")\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7c8318",
   "metadata": {},
   "source": [
    "\n",
    "### 2.4. Generation\n",
    "\n",
    "![](../img/overview-retrieval.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Prompt\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# LLM\n",
    "llm = OllamaLLM(model=\"deepseek-r1:8b\")\n",
    "\n",
    "# Chain\n",
    "chain = prompt | llm\n",
    "\n",
    "# Run\n",
    "chain.invoke({\"context\":docs,\"question\":\"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c8b73b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "也可以使用封装的 prompt 模板，同时，构造完整的 RAG Chain："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c84bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Pull a pre-made RAG prompt from LangChain Hub\n",
    "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(\"prompt_hub_rag: \" + str(prompt_hub_rag))\n",
    "\n",
    "# RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bad8867",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "关联资料\n",
    "\n",
    "* [rag-from-scratch](https://github.com/langchain-ai/rag-from-scratch)\n",
    "* [rag-ecosystem](https://github.com/FareedKhan-dev/rag-ecosystem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragEco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
